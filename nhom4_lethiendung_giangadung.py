# -*- coding: utf-8 -*-
"""Nhom4_LETHIENDUNG_GIANGADUNG

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IhqaC9eXANdz2vzSFaS7qUEyp2-LeV-v
"""

# ========================
# TRỰC QUAN HÓA
# ========================

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Load dữ liệu
df = pd.read_csv("arXiv_scientific dataset.csv")

print("📊 Kích thước dữ liệu:", df.shape)

# 2. Xác định cột nhãn
target_col = "category"   # ⚠️ đổi nếu cột nhãn có tên khác

if target_col in df.columns:
    label_counts = df[target_col].value_counts()

    print("\n🔹 Tổng số nhãn:", df[target_col].nunique())
    print("🔹 Tổng số mẫu:", df.shape[0])

    # Lấy top 10 nhãn nhiều mẫu nhất
    top_n = 10
    top_labels = label_counts.head(top_n)

    print(f"\n📌 Top {top_n} nhãn có nhiều mẫu nhất:")
    print(top_labels)

    # 3. Biểu đồ cột
    plt.figure(figsize=(10,5))
    sns.barplot(x=top_labels.index, y=top_labels.values, palette="viridis")
    plt.title(f"Số lượng mẫu theo Top {top_n} nhãn")
    plt.ylabel("Số mẫu")
    plt.xlabel("Nhãn")
    plt.xticks(rotation=45, ha="right")
    plt.show()
else:
    print("⚠️ Không tìm thấy cột 'category'. Vui lòng kiểm tra lại tên cột nhãn trong dữ liệu!")

# ========================
# Làm sạch dữ liệu
# HIỂN THỊ DỮ LIỆU TRƯỚC & SAU KHI LÀM SẠCH
# ========================

import pandas as pd

# 1. Load dữ liệu
df = pd.read_csv("arXiv_scientific dataset.csv")

print("📊 Kích thước dữ liệu ban đầu:", df.shape)

# 2. Hiển thị 10 dòng đầu tiên trước khi làm sạch
print("\n📌 10 dòng dữ liệu ban đầu (chưa làm sạch):")
print(df.head(10))

# 3. Làm sạch dữ liệu
df_cleaned = df.dropna()              # Xóa giá trị thiếu
df_cleaned = df_cleaned.drop_duplicates()  # Xóa trùng lặp
df_cleaned.columns = df_cleaned.columns.str.strip()  # Chuẩn hóa tên cột

print("\n✅ Kích thước dữ liệu sau khi làm sạch:", df_cleaned.shape)

# 4. Hiển thị 10 dòng đầu tiên sau khi làm sạch
print("\n📌 10 dòng dữ liệu sau khi làm sạch:")
print(df_cleaned.head(10))

# ========================
# CHUẨN HOÁ DỮ LIỆU
# ========================

import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder

# 1. Load và làm sạch dữ liệu trước
df = pd.read_csv("arXiv_scientific dataset.csv")
df = df.dropna().drop_duplicates()   # Xóa giá trị thiếu và dòng trùng lặp
df.columns = df.columns.str.strip()  # Chuẩn hóa tên cột

# 2. Xác định đặc trưng số (X) và nhãn (y)
dac_trung_so = ['summary_word_count']   # ⚠️ Nếu có nhiều cột số thì thêm vào đây

X = df[dac_trung_so]   # Chỉ lấy đặc trưng dạng số
y = df["category"]

# 3. Mã hóa nhãn nếu là dạng text
if y.dtype == "object":
    le = LabelEncoder()
    y_mahoa = le.fit_transform(y)

# 4. Chuẩn hóa đặc trưng bằng StandardScaler
scaler = StandardScaler()
X_chuanhoa = scaler.fit_transform(X)

# 5. In 10 dòng dữ liệu ban đầu (chưa chuẩn hóa)
print("📌 10 dòng dữ liệu ban đầu (chưa chuẩn hóa):")
print(X.head(10))

# 6. In 10 dòng dữ liệu sau khi chuẩn hóa
print("\n📌 10 dòng dữ liệu sau khi chuẩn hóa:")
print(X_chuanhoa[:10])

# ========================
# SO SÁNH VECTOR HÓA VĂN BẢN
# ========================

import pandas as pd
import time
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sentence_transformers import SentenceTransformer
from sklearn.model_selection import train_test_split

# 1. Load và làm sạch dữ liệu
df = pd.read_csv("arXiv_scientific dataset.csv")
df = df.dropna().drop_duplicates()
df.columns = df.columns.str.strip()

# 2. Giới hạn số mẫu để chạy nhanh hơn
df_sample = df.sample(2000, random_state=42)
texts = df_sample["summary"].astype(str).tolist()

# Lưu kết quả so sánh
results = []

# 3. Bag-of-Words
start = time.time()
vectorizer_bow = CountVectorizer(max_features=5000)
X_bow = vectorizer_bow.fit_transform(texts)
end = time.time()
results.append(["Bag-of-Words", X_bow.shape, end-start, "Yếu (mất ngữ nghĩa)"])

# 4. TF-IDF
start = time.time()
vectorizer_tfidf = TfidfVectorizer(max_features=5000)
X_tfidf = vectorizer_tfidf.fit_transform(texts)
end = time.time()
results.append(["TF-IDF", X_tfidf.shape, end-start, "Trung bình (có trọng số, nhưng mất ngữ cảnh)"])

# 5. Sentence Embeddings
start = time.time()
model = SentenceTransformer('all-MiniLM-L6-v2')
X_embed = model.encode(texts, show_progress_bar=True)
end = time.time()
results.append(["Sentence Embeddings", X_embed.shape, end-start, "Tốt (giữ được ngữ nghĩa)"])

# 6. Xuất bảng so sánh
df_compare = pd.DataFrame(results, columns=["Phương pháp", "Kích thước ma trận", "Thời gian (giây)", "Đánh giá"])
print("\n📊 BẢNG SO SÁNH CÁC VECTOR HÓA\n")
print(df_compare)

# 7. Chọn mô hình tốt nhất -> Sentence Embeddings
print("\n✅ Chọn mô hình tốt nhất: Sentence Embeddings (all-MiniLM-L6-v2)\n")

# 8. Chia tập train/test để sử dụng về sau
X_train, X_test = train_test_split(X_embed, test_size=0.2, random_state=42)
print("📌 Tập train:", X_train.shape)
print("📌 Tập test :", X_test.shape)

# ========================
# THUẬT TOÁN KNN
# ========================

import pandas as pd
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
import seaborn as sns
import matplotlib.pyplot as plt
from sentence_transformers import SentenceTransformer

# 1. Load dữ liệu
df = pd.read_csv("arXiv_scientific dataset.csv")
df = df.dropna().drop_duplicates()
df.columns = df.columns.str.strip()

# 2. Lấy mẫu nhỏ để chạy nhanh
df_sample = df.sample(2000, random_state=42)

texts = df_sample["summary"].astype(str).tolist()
labels = df_sample["category"].astype(str).tolist()   # nhãn là category

# 3. Sentence Embedding
model = SentenceTransformer('all-MiniLM-L6-v2')
X_embed = model.encode(texts, show_progress_bar=True)

# 4. Chia dữ liệu train/test
X_train, X_test, y_train, y_test = train_test_split(X_embed, labels, test_size=0.2, random_state=42)

# 5. Huấn luyện KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

# 6. Dự đoán
y_pred = knn.predict(X_test)

# 7. Đánh giá mô hình
print("\n🔹 Kết quả KNN:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# 8. Vẽ ma trận nhầm lẫn
cm = confusion_matrix(y_test, y_pred, labels=knn.classes_)
plt.figure(figsize=(10,7))
sns.heatmap(cm, annot=False, cmap="Blues", xticklabels=knn.classes_, yticklabels=knn.classes_)
plt.xlabel("Dự đoán")
plt.ylabel("Thực tế")
plt.title("Ma trận nhầm lẫn - KNN")
plt.show()

# ========================
# THUẬT TOÁN NAIVE BAYES
# ========================

import pandas as pd
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
import seaborn as sns
import matplotlib.pyplot as plt
from sentence_transformers import SentenceTransformer

# 1. Load dữ liệu
df = pd.read_csv("arXiv_scientific dataset.csv")
df = df.dropna().drop_duplicates()
df.columns = df.columns.str.strip()

# 2. Lấy mẫu nhỏ để chạy nhanh
df_sample = df.sample(2000, random_state=42)

texts = df_sample["summary"].astype(str).tolist()
labels = df_sample["category"].astype(str).tolist()

# 3. Sentence Embedding
model = SentenceTransformer('all-MiniLM-L6-v2')
X_embed = model.encode(texts, show_progress_bar=True)

# 4. Chia dữ liệu train/test
X_train, X_test, y_train, y_test = train_test_split(X_embed, labels, test_size=0.2, random_state=42)

# 5. Huấn luyện Naive Bayes
nb = GaussianNB()
nb.fit(X_train, y_train)

# 6. Dự đoán
y_pred = nb.predict(X_test)

# 7. Đánh giá mô hình
print("\n🔹 Kết quả Naive Bayes:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# 8. Chỉ lấy top 10 nhãn phổ biến nhất
top_labels = pd.Series(y_test).value_counts().nlargest(10).index.tolist()

y_test_filtered = ["Other" if lbl not in top_labels else lbl for lbl in y_test]
y_pred_filtered = ["Other" if lbl not in top_labels else lbl for lbl in y_pred]

# 9. Vẽ ma trận nhầm lẫn gọn
cm = confusion_matrix(y_test_filtered, y_pred_filtered, labels=top_labels+["Other"])
plt.figure(figsize=(10,7))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=top_labels+["Other"],
            yticklabels=top_labels+["Other"])
plt.xlabel("Dự đoán")
plt.ylabel("Thực tế")
plt.title("Ma trận nhầm lẫn (Top 10 lớp chính + Other) - Naive Bayes")
plt.show()

# ========================
# THUẬT TOÁN CÂY QUYẾT ĐỊNH
# ========================

import pandas as pd
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
import seaborn as sns
import matplotlib.pyplot as plt
from sentence_transformers import SentenceTransformer

# 1. Load dữ liệu
df = pd.read_csv("arXiv_scientific dataset.csv")
df = df.dropna().drop_duplicates()
df.columns = df.columns.str.strip()

# 2. Lấy mẫu nhỏ để chạy nhanh
df_sample = df.sample(2000, random_state=42)

texts = df_sample["summary"].astype(str).tolist()
labels = df_sample["category"].astype(str).tolist()

# 3. Sentence Embedding
model = SentenceTransformer('all-MiniLM-L6-v2')
X_embed = model.encode(texts, show_progress_bar=True)

# 4. Chia dữ liệu train/test
X_train, X_test, y_train, y_test = train_test_split(
    X_embed, labels, test_size=0.2, random_state=42
)

# 5. Huấn luyện Decision Tree
dt = DecisionTreeClassifier(random_state=42, max_depth=20)  # giới hạn độ sâu để tránh overfitting
dt.fit(X_train, y_train)

# 6. Dự đoán
y_pred = dt.predict(X_test)

# 7. Đánh giá mô hình
print("\n🔹 Kết quả Decision Tree:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# 8. Chỉ lấy top 10 nhãn phổ biến nhất
top_labels = pd.Series(y_test).value_counts().nlargest(10).index.tolist()

y_test_filtered = ["Other" if lbl not in top_labels else lbl for lbl in y_test]
y_pred_filtered = ["Other" if lbl not in top_labels else lbl for lbl in y_pred]

# 9. Vẽ ma trận nhầm lẫn gọn
cm = confusion_matrix(y_test_filtered, y_pred_filtered, labels=top_labels+["Other"])
plt.figure(figsize=(10,7))
sns.heatmap(cm, annot=True, fmt="d", cmap="Oranges",
            xticklabels=top_labels+["Other"],
            yticklabels=top_labels+["Other"])
plt.xlabel("Dự đoán")
plt.ylabel("Thực tế")
plt.title("Ma trận nhầm lẫn (Top 10 lớp chính + Other) - Decision Tree")
plt.show()

# ========================
# THUẬT TOÁN K-MEANS
# ========================

import pandas as pd
from sklearn.cluster import KMeans
from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score
from sentence_transformers import SentenceTransformer
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Load dữ liệu
df = pd.read_csv("arXiv_scientific dataset.csv")
df = df.dropna().drop_duplicates()
df.columns = df.columns.str.strip()

# 2. Lấy mẫu nhỏ để chạy nhanh
df_sample = df.sample(2000, random_state=42)

texts = df_sample["summary"].astype(str).tolist()
labels = df_sample["category"].astype(str).tolist()

# 3. Sentence Embedding
model = SentenceTransformer('all-MiniLM-L6-v2')
X_embed = model.encode(texts, show_progress_bar=True)

# 4. Huấn luyện K-Means
num_clusters = len(set(labels))  # số cụm = số nhãn thực
kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)
y_pred = kmeans.fit_predict(X_embed)

# 5. Đánh giá bằng chỉ số clustering
ari = adjusted_rand_score(labels, y_pred)
nmi = normalized_mutual_info_score(labels, y_pred)

print("\n🔹 Kết quả K-Means:")
print("Adjusted Rand Index (ARI):", ari)
print("Normalized Mutual Information (NMI):", nmi)

# 6. Vẽ phân bố cụm theo nhãn thật (top 10 nhãn)
df_vis = pd.DataFrame({"True_Label": labels, "Cluster": y_pred})
top_labels = df_vis["True_Label"].value_counts().nlargest(10).index.tolist()
df_vis_filtered = df_vis[df_vis["True_Label"].isin(top_labels)]

plt.figure(figsize=(10,6))
sns.countplot(data=df_vis_filtered, x="Cluster", hue="True_Label", palette="tab10")
plt.title("Phân bố cụm theo nhãn thật (Top 10 nhãn) - KMeans")
plt.xlabel("Cụm KMeans")
plt.ylabel("Số lượng mẫu")
plt.legend(title="Nhãn thật", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

import matplotlib.pyplot as plt

# Kết quả mô hình (bạn thay số Accuracy của Decision Tree cho đúng thực tế)
results = {
    "KNN": 0.67,
    "Naive Bayes": 0.645,
    "Decision Tree": 0.66,
    "K-Means (NMI)": 0.374
}

# Vẽ biểu đồ
plt.figure(figsize=(8,5))
bars = plt.bar(results.keys(), results.values(),
               color=["#4CAF50","#2196F3","#FF9800","#9C27B0"],
               width=0.6, edgecolor="black", linewidth=1)

# Thêm giá trị trên cột
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.015,
             f"{yval:.3f}", ha='center', fontsize=11, fontweight="bold")

# Tùy chỉnh trục
plt.ylabel("Độ chính xác / Chỉ số NMI", fontsize=12)
plt.title("So sánh hiệu quả các mô hình học máy", fontsize=14, fontweight="bold")
plt.ylim(0,1)
plt.grid(axis="y", linestyle="--", alpha=0.7)

plt.show()